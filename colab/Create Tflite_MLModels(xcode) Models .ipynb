{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPoSaLpaNZk9APICjPe7LYd"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["[GPU supported operations](https://www.tensorflow.org/lite/performance/gpu)"],"metadata":{"id":"nyuDYpK35C4k"}},{"cell_type":"code","source":["!pip install tensorflow==2.10.0\n","!pip install coremltools\n","!pip install pytablewriter"],"metadata":{"id":"G3n4DF6mBaui"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","id":"Jt54UXvm3pd4"},"outputs":[],"source":["#@markdown libs\n","\n","import os\n","# stop tf warning logs\n","os.environ[\"KMP_SETTINGS\"] = \"false\"\n","import coremltools as ct \n","\n","from google.colab import files\n","\n","import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras import layers\n","\n","import pickle\n","from google.colab import files\n","\n","import numpy as np\n","from shutil import copyfile\n","from numpy.linalg import norm\n","\n","import time\n","\n","import json\n","from glob import glob\n","\n","import sys\n","import time\n","\n","import matplotlib.pyplot as plt\n","import random\n","from os.path import join\n","import json\n","\n","from math import ceil\n","\n","from datetime import datetime\n","import gdown\n","\n","\n","plt.rcParams['figure.figsize'] = [25, 4]"]},{"cell_type":"code","source":["#@markdown funcs\n","\n","def get_tflite_from_keras(keras_model, tflite_name='model.tflite', optimize_default=False):\n","    keras_model.save('model_di')\n","    converter_model_keras = tf.lite.TFLiteConverter.from_saved_model('model_di')\n","    if optimize_default==True:\n","        converter_model_keras.optimizations = [tf.lite.Optimize.DEFAULT]\n","\n","    converter_model_keras = converter_model_keras.convert()\n","    with open(tflite_name, 'wb') as f:\n","        f.write(converter_model_keras)\n","\n","    interpreter = tf.lite.Interpreter(model_path=tflite_name)\n","    interpreter.allocate_tensors()\n","    print(interpreter.get_input_details())\n","    print(interpreter.get_output_details())\n","    return interpreter\n","\n","def convertKeras2MLModel(kerasModel):\n","    mlmodel = ct.convert(kerasModel)\n","    mlmodel.save(kerasModel.fileName+'.mlmodel')\n","    input = str(mlmodel.input_description)\n","    return input[len('Features('):-1]"],"metadata":{"cellView":"form","id":"N2UFja7q4nVJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#@title Models\n","from tensorflow.keras.layers import Dense, Conv2D, LSTM, MultiHeadAttention, LayerNormalization\n","\n","#@markdown DenseModel\n","\n","class DenseModel(keras.Model):\n","    def __init__(self, n_units=512, n_layers=10):\n","        super(DenseModel, self).__init__()\n","        self.ffn = keras.Sequential(\n","            [Dense(units=n_units, activation='relu', use_bias=False) for _ in range(n_layers)]\n","        ) \n","        self.fileName = f'DenseModel_units_{n_units}_layers_{n_layers}_'\n","\n","    def call(self, inputs):\n","        return self.ffn(inputs)\n","\n","#@markdown ConvModel\n","\n","class ConvModel(keras.Model):\n","    def __init__(self, filters=32, n_layers=10, kernel_size=3):\n","        super(ConvModel, self).__init__()\n","        self.seq = keras.Sequential(\n","            [Conv2D(filters=filters,\n","                        kernel_size=kernel_size,\n","                        activation='relu',\n","                        use_bias=False,\n","                        padding=\"same\",) for _ in range(n_layers)]\n","        ) \n","        self.fileName = f'Conv2D_filters_{filters}_kernel_{kernel_size}_layers_{n_layers}_'\n","    def call(self, inputs):\n","        return self.seq(inputs)\n","\n","\n","#@markdown Transformer\n","\n","\n","class TransformerDecoderLayer(tf.keras.layers.Layer):\n","    def __init__(self, embed_dim=512,\n","                 num_heads=6, feed_forward_dim=2048,\n","                 key_dim=64):\n","        super(TransformerDecoderLayer, self).__init__()\n","        self.layernorm1 = layers.LayerNormalization(epsilon=1e-6)\n","        self.layernorm2 = layers.LayerNormalization(epsilon=1e-6)\n","        self.layernorm3 = layers.LayerNormalization(epsilon=1e-6)\n","        self.self_att = layers.MultiHeadAttention(\n","            num_heads=num_heads, key_dim=key_dim\n","        )\n","        self.enc_att = layers.MultiHeadAttention(num_heads=num_heads, key_dim=key_dim)\n","        self.ffn = keras.Sequential(\n","            [\n","                layers.Dense(feed_forward_dim, activation='relu', use_bias=False),\n","                layers.Dense(embed_dim, use_bias=False),\n","            ]\n","        )\n","\n","    def call(self, enc_out, target):\n","        target_norm = self.layernorm1(target)\n","        target_att = self.self_att(target_norm, target_norm)\n","        target_norm = self.layernorm2(target + target_att)\n","        enc_out = self.enc_att(target_norm, enc_out)\n","        enc_out_norm = self.layernorm3(enc_out + target_norm)\n","        ffn_out = self.ffn(enc_out_norm)\n","        output = enc_out_norm + ffn_out\n","        return output\n","        \n","class TransformerEncoderLayer(tf.keras.layers.Layer):\n","    def __init__(self, embed_dim=512,\n","                 num_heads=6, feed_forward_dim=2048,\n","                 key_dim=64):\n","        super(TransformerEncoderLayer, self).__init__()\n","        self.att = MultiHeadAttention(num_heads=num_heads,\n","                                             key_dim=key_dim)\n","        self.ffn = keras.Sequential(\n","            [\n","                Dense(feed_forward_dim, activation='relu', use_bias=False),\n","                Dense(embed_dim, use_bias=False),\n","            ]\n","        ) \n","        self.layernorm1 = layers.LayerNormalization(epsilon=1e-6)\n","        self.layernorm2 = layers.LayerNormalization(epsilon=1e-6)\n","\n","    def call(self, inputs):\n","        attn_output = self.att(inputs, inputs)\n","        out1 = self.layernorm1(inputs + attn_output)\n","        ffn_output = self.ffn(out1)\n","        output=self.layernorm2(inputs + ffn_output)\n","        return output\n","\n","class TransformerEncoder(keras.Model):\n","    def __init__(self, n_layers=8, embed_dim=512,\n","                 num_heads=6, feed_forward_dim=2048,\n","                 key_dim=64):\n","        super(TransformerEncoder, self).__init__()\n","\n","        self.encoder = keras.Sequential(\n","            [TransformerEncoderLayer(embed_dim=embed_dim, num_heads=num_heads,\n","                                   feed_forward_dim=feed_forward_dim, key_dim=key_dim)\n","                for _ in range(n_layers)\n","            ]\n","        )\n","    def call(self, inputs):\n","        return self.encoder(inputs)\n","\n","class Transformer(keras.Model):\n","    def __init__(\n","        self,\n","        embed_dim=512,\n","        num_heads=6,\n","        feed_forward_dim=2048,\n","        key_dim=64,\n","        num_layers_enc=1,\n","        num_layers_dec=1,\n","        num_classes=2,\n","    ):\n","        super().__init__()\n","        self.num_layers_dec=num_layers_dec\n","        self.encoder = TransformerEncoder(n_layers=num_layers_enc,\n","                                          embed_dim=embed_dim,\n","                                          num_heads=num_heads,\n","                                          feed_forward_dim=feed_forward_dim,\n","                                          key_dim=key_dim)\n","\n","        for i in range(num_layers_dec):\n","            setattr(\n","                self,\n","                f\"dec_layer_{i}\",\n","                TransformerDecoderLayer(embed_dim=embed_dim,\n","                                        num_heads=num_heads,\n","                                        feed_forward_dim=feed_forward_dim,\n","                                        key_dim=key_dim),\n","                    )\n","\n","        self.classifier = layers.Dense(num_classes)\n","        self.fileName = f'Transformer_embedDim_{embed_dim}_nHeads_{num_heads}_ffn_{feed_forward_dim}_keyDim_{key_dim}_layers_{num_layers_enc}_deLayers_{num_layers_dec}_'\n","\n","    def decode(self, enc_out, target):\n","        for i in range(self.num_layers_dec):\n","            target = getattr(self, f\"dec_layer_{i}\")(enc_out, target)\n","        return target\n","\n","\n","    def call(self, inputs):\n","        x = self.encoder(inputs)\n","        y = self.decode(x, inputs)\n","        return self.classifier(y)\n","\n","\n","#@markdown Mel spectrogram\n","\n","from librosa.filters import mel as mel_filter\n","from librosa.util import pad_center\n","from scipy.signal import get_window\n","\n","def get_forward_basis(filter_length=2048, window='hann'):\n","\n","    win_length = filter_length\n","    # window='hann' # blackmanharris hann\n","    fourier_basis = np.fft.fft(np.eye(filter_length))\n","\n","    cutoff = int((filter_length / 2 + 1))\n","    fourier_basis = np.vstack([np.real(fourier_basis[:cutoff, :]),\n","                                np.imag(fourier_basis[:cutoff, :])])\n","\n","    forward_basis = fourier_basis[:, None, :]\n","    forward_basis_c = forward_basis.copy()\n","\n","    fft_window = get_window(window, win_length, fftbins=True, )\n","    fft_window = pad_center(fft_window, filter_length)\n","    forward_basis *= fft_window\n","    forward_basis = forward_basis.T.astype(np.float32)\n","    forward_basis = np.expand_dims(forward_basis, 0)\n","    forward_basis = tf.convert_to_tensor(forward_basis)\n","\n","    return forward_basis\n","\n","def get_mel_filter(sample_rate=16000, filter_length=2048, n_mels=229, mel_fmin=30, mel_fmax=8000, htk=True):\n","\n","    mel_basis =  mel_filter(sample_rate, filter_length, n_mels, mel_fmin, mel_fmax, htk=htk)\n","    mel_basis = tf.convert_to_tensor(mel_basis)\n","\n","    return mel_basis\n","\n","class mel_tf_for_tflite(tf.keras.Model):\n","        \n","    def __init__(self, filters, mel_basis, hop_size=512, num_samples=1535):\n","        super(mel_tf_for_tflite, self).__init__()\n","        self.filters = filters\n","        self.mel_basis = mel_basis\n","        self.hop_size = hop_size\n","        self.num_samples = num_samples\n","        self.window_size =  filters.shape[1]\n","        ms = int((num_samples/16000) * 1000)\n","        self.fileName = f'MelSpecTF_{self.window_size}_{ms}_'\n","\n","    def call(self, input_data):\n","\n","        dim2 = int(self.num_samples/self.hop_size) + 1\n","        input_data = tf.pad(input_data, ([0, 0], [int(self.window_size / 2), int(self.window_size / 2)]), mode='REFLECT') # norm with torch zero\n","        input_data = tf.expand_dims(input_data, -1)\n","        input_data = tf.expand_dims(input_data, 1)\n","        forward_transform = tf.nn.conv2d(\n","        input_data, self.filters, self.hop_size, 'VALID')\n","        forward_transform = tf.squeeze(forward_transform)\n","        forward_transform = tf.transpose(forward_transform)\n","        forward_transform = tf.reshape(forward_transform, [1, self.window_size + 2, dim2])\n","        real_part = forward_transform[:, :(self.window_size+2) // 2, :]\n","        imag_part = forward_transform[:, (self.window_size+2) // 2:, :]\n","        magnitude = tf.math.sqrt(real_part**2 + imag_part**2)\n","        mel_output = tf.matmul(self.mel_basis, magnitude)\n","        mel_output = tf.math.log(tf.clip_by_value(mel_output, clip_value_min =1e-5 , clip_value_max=np.inf))\n","\n","        mel_output = tf.transpose(mel_output)\n","\n","        return mel_output"],"metadata":{"cellView":"form","id":"ufzI-CsJ6Vwx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#@markdown test all model's classes\n","model = ConvModel(n_layers=12, filters=256, kernel_size=3)\n","print(model(np.random.random((1, 10, 512, 3)).astype(float)).shape, model.fileName)\n","model = DenseModel(n_layers=10, n_units=3)\n","print(model(np.random.random((1, 10, 512)).astype(float)).shape, model.fileName)\n","model = Transformer(embed_dim=512,\n","                    num_heads=6,\n","                    feed_forward_dim=2048,\n","                    key_dim=64,\n","                    num_layers_enc=1,\n","                    num_layers_dec=1,\n","                    num_classes=2,\n","                    )\n","print(model(np.random.random((1, 10, 512)).astype(float)).shape, model.fileName)\n","model = EncoderLstm(embed_dim=512,\n","                    num_heads=6,\n","                    feed_forward_dim=2048,\n","                    key_dim=64,\n","                    num_layers_enc=1,\n","                    n_lstm_units=512,\n","                    num_classes=2,\n","                    )\n","print(model(np.random.random((1, 10, 512)).astype(float)).shape, model.fileName)\n","\n","filters = get_forward_basis(filter_length=4096)\n","mel_basis = get_mel_filter(n_mels=512, filter_length=4096)\n","mel_tf_model = mel_tf_for_tflite(filters,\n","                    mel_basis,\n","                    num_samples=512*32 - 1)\n","\n","mel_tf_model(np.random.random((1, 512*32 - 1 ))).shape, mel_tf_model.fileName"],"metadata":{"cellView":"form","id":"EcSuWWIGMKyN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Create models\n","\n","# Models parameters\n","Dense_models_config = [[6, 128], [3, 256]]\n","Conv_models_config = [[6, 128, 3], [3, 36, 12]]\n","Transformer_models_config = [[512, 6, 1024, 64, 8, 8, 512]]\n","\n","Models_info = []\n","Input = np.ones((1, 10, 512, 3)).astype(float)\n","\n","mlmodel_input_name='input_1'\n","\n","\n","for n_layers, filters, kernel_size in Conv_models_config:\n","    input = Input\n","    model = ConvModel(n_layers=n_layers, filters=filters, kernel_size=kernel_size)\n","    output = model(input).numpy()\n","\n","    mlmodel_input_name = convertKeras2MLModel(model)\n","    get_tflite_from_keras(model, model.fileName+'.tflite')\n","    Models_info.append([model.fileName+'.tflite', model.fileName+'.mlmodel', mlmodel_input_name, input.shape, model.count_params(), output.sum()])\n","    del model\n","\n","\n","\n","for embed_dim, num_heads, feed_forward_dim, key_dim, num_layers_enc, num_layers_dec, num_classes in Transformer_models_config:\n","    input = Input[:,:,:,0]\n","    model = model = Transformer(embed_dim=embed_dim,\n","                    num_heads=num_heads,\n","                    feed_forward_dim=feed_forward_dim,\n","                    key_dim=key_dim,\n","                    num_layers_enc=num_layers_enc,\n","                    num_layers_dec=num_layers_dec,\n","                    num_classes=num_classes,\n","                    )\n","    output = model(input).numpy()\n","\n","    get_tflite_from_keras(model, model.fileName+'.tflite')\n","    mlmodel_input_name = convertKeras2MLModel(model)\n","    Models_info.append([model.fileName+'.tflite', model.fileName+'.mlmodel', mlmodel_input_name, input.shape, model.count_params(), output.sum()])\n","    del model\n","\n","for n_layers, n_units in Dense_models_config:\n","    input = Input[:,:,:,0]\n","    model = DenseModel(n_layers=n_layers, n_units=n_units)\n","    output = model(input).numpy()\n","\n","    mlmodel_input_name = convertKeras2MLModel(model)\n","    get_tflite_from_keras(model, model.fileName+'.tflite')\n","    Models_info.append([model.fileName+'.tflite', model.fileName+'.mlmodel', mlmodel_input_name, input.shape, model.count_params(), output.sum()])\n","    del model\n","\n","\n","# Mel spectro part\n","filters = get_forward_basis(filter_length=4096)\n","mel_basis = get_mel_filter(n_mels=512, filter_length=4096)\n","model = mel_tf_for_tflite(filters,\n","                    mel_basis,\n","                    num_samples=512*32 - 1)\n","mel_input = np.ones((1, 512*32 - 1 ))\n","output = model(mel_input).numpy()\n","mlmodel_input_name = convertKeras2MLModel(model)\n","get_tflite_from_keras(model, model.fileName+'.tflite')\n","\n","Models_info.append([model.fileName+'.tflite', model.fileName+'.mlmodel', mlmodel_input_name, mel_input.shape, model.count_params(), output.sum()])\n","\n","Models_info"],"metadata":{"id":"QkocQhTUs6nK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["Models_info_str = []\n","for i in Models_info:\n","    temp = []\n","    for j in i:\n","        temp.append(str(j))\n","    Models_info_str.append(temp)\n","\n","np.savetxt('First_Batch_Models_Info.txt',np.array(Models_info_str).astype(str), fmt='%s', delimiter='<<<')"],"metadata":{"id":"02gwHp8n0naC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["Models_info_str = np.loadtxt('First_Batch_Models_Info.txt', dtype=str, delimiter='<<<', )\n","Models_info_str[0]"],"metadata":{"id":"qq5X7ISQtaOI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","#@markdown **swiftMLModelFuncString** is a template for a function that run (mlmodel) with Swift\n","swiftMLModelFuncString = '''\n","func run-MODELNAME-NTimes(input: MLMultiArray, n_rounds: Int = 10, ignoreFirst: Bool=true, mlConfig: MLModelConfiguration) -> String{\n","    \n","    var invokingDurations = [] as [Double]\n","    var firtInvokeDuration = 0.0\n","    var initDuration = 0.0\n","    let timer = Timer()\n","    var _sum = Float(0.0)\n","    \n","    do{\n","        /// Initialize model\n","        timer.reset()\n","        let mlModel = try -MODELNAME-(configuration: mlConfig)\n","        initDuration = timer.getDurationAndReset()\n","        \n","        /// Run same input n times\n","        for i in 0..<n_rounds{\n","            timer.reset()\n","            let output = try mlModel.prediction(input_1: input).Identity\n","            if i==0 {\n","                firtInvokeDuration=timer.getDuration()\n","                if ignoreFirst {\n","                    continue\n","                }\n","            }\n","            invokingDurations.append(timer.getDuration())\n","            _sum = sumMultiArray(array:output)\n","        }\n","    }catch {\n","        print(\"runCoreMLModelNTimes error\", error)\n","    }\n","  \n","    let invokeAvgDuration = invokingDurations.avg()\n","    let invokeStdDuration = invokingDurations.std()\n","    \n","    return \"-MODELNAME-, \\(invokeAvgDuration), \\(invokeStdDuration), \\(firtInvokeDuration), \\(initDuration), \\(_sum)\"\n","        \n","}\n","'''\n","\n","\n","#@markdown **swiftMLModelCallingString** template for the code to run the above mentioned template\n","swiftMLModelCallingString = '''\n","\n","modelDurations = run-MODELNAME-NTimes(input: -MODELINPUT-, n_rounds: n_rounds, mlConfig:mlConfig)\n","lines.append(modelDurations+computeUnitsName)\n","\n","'''\n","\n","#@markdown -MODELNAME- should be replaced with the model name\n","#@markdown -MODELINPUT- should be replaced with the model input MLMultiArray with the same input shape within calling code\n","\n","# swiftMLModelFuncString.replace(\"-MODELNAME-\", 't')"],"metadata":{"cellView":"form","id":"M8uWgFeeaxXg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Get swift code for dealing with the created models\n","Swift_new_funcs_str = ''\n","Swift_call_str = ''\n","for item in Models_info:\n","    name = item[0].split('.')[0]\n","    if item[2]!='input_1':\n","        print('ERRORR ', item)\n","    \n","    Swift_new_funcs_str += '\\n\\n\\n'\n","    Swift_new_funcs_str += swiftMLModelFuncString.replace(\"-MODELNAME-\", name)\n","\n","    Swift_call_str += swiftMLModelCallingString.replace(\"-MODELNAME-\", name)"],"metadata":{"id":"D87UuBmB1M5d"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["Swift_call_str"],"metadata":{"id":"1jdTK6NQyjJx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["Swift_new_funcs_str"],"metadata":{"id":"L0_ImS8PBAvE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!rm First_Batch_of_models_speed_test_on_iOS.zip"],"metadata":{"id":"jao17ivmyImA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!zip First_Batch_of_models_speed_test_on_iOS.zip *tflite *mlmodel"],"metadata":{"id":"7RlwIZIbVlMk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!mv First_Batch_of_models_speed_test_on_iOS.zip path/to/drive # faster to download from drive than from colab directly"],"metadata":{"id":"thc1BiTpbzK2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data = np.loadtxt('CA1748D9-13CF-40EA-B048-B6CA584ADD5A.txt', delimiter=', ', dtype=str)\n","\n","computeUnits_dic= {}\n","computeUnits_dic['MLComputeUnits.cpuOnly'] = 1\n","computeUnits_dic['MLComputeUnits.cpuAndGPU'] = 2\n","computeUnits_dic['MLComputeUnits.all'] = 3\n","computeUnits_dic['MLComputeUnits.cpuAndNeuralEngine'] = 4\n","computeUnits_dic['Tflite-CPU'] = 5\n","computeUnits_dic['Tflite-GPU'] = 6\n","\n","modelNames = data[1:,0]\n","invokeDurations = data[1:, 2].astype(float)"],"metadata":{"id":"ZUcVnn_iJnPu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["models_name = list(set(list(data[1:,0])))\n","n_models =  len(models_name)\n","n_headers = len(headers)\n","\n","row = [\"-/-\" for _ in range(n_headers)]\n","table_content = [row for _ in range(n_models)]\n","\n","\n","table_content = []\n","for row_i in range(n_models ):\n","    model_name = models_name[row_i]\n","    row = [model_name]\n","    models_indexes = np.where(data[:,0]==model_name)\n","    models_rows = data[models_indexes]\n","    models_computeUnitesNames = list(models_rows[:,-1])\n","    for computeUnite_name in computeUnits_dic:\n","        if computeUnite_name in models_computeUnitesNames:\n","            models_rows_row_i = models_computeUnitesNames.index(computeUnite_name)\n","            try:\n","                invokeAvg = float(models_rows[models_rows_row_i][1]) # in sec\n","                invokeStd = float(models_rows[models_rows_row_i][2])\n","                if invokeStd == 0.0:\n","                    if models_rows[models_rows_row_i][1] == 'nan':\n","                        row.append('NaN')  \n","                    else:\n","                        row.append(f'{invokeAvg*1000:.1f}/<0.1')\n","                else:\n","                    row.append(f'{invokeAvg*1000:.1f}/{invokeStd*1000:.1f}')\n","            except Exception as e:\n","                    row.append(f'NaN')\n","        else:\n","            row.append(f'-/-')\n","\n","    table_content.append(row)\n","\n","\n","\n","\n","len(table_content), table_content[0]"],"metadata":{"id":"XhHyNlZYsnA_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from pytablewriter import MarkdownTableWriter\n","headers=[\"Model name\", \"CoreML-CPU\",\t\"CoreML-CPU&GPU\",\t\"CoreML-All\",\t\"CoreML-CPU&NeuralEngine\",\t\"Tflite-CPU\",\t\"Tflite-GPU\"]\n","writer = MarkdownTableWriter(\n","    \n","    table_name=data[0][-1].split('-')[1],\n","    headers=[\"Model name\", \"CoreML-CPU\",\t\"CoreML-CPU&GPU\",\t\"CoreML-All\",\t\"CoreML-CPU&NeuralEngine\",\t\"Tflite-CPU\",\t\"Tflite-GPU\"],\n","    value_matrix=table_content,\n",")\n","s = writer.write_table()\n","s\n","print('')"],"metadata":{"id":"ZfexCzW2rNC7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"vZriQk7ciYDR"},"execution_count":null,"outputs":[]}]}
